{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract pillow torch torchvision\n"
      ],
      "metadata": {
        "id": "4lyT3SAK6FrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "pxb_YH_z6Fku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfREMY0MMl1Y",
        "outputId": "68421c9e-bdae-4ffc-957e-dc8119ad868d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install tqdm pillow requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AK7MITVlG_o_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the train and test CSV files\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/dataset/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/dataset/test.csv')\n",
        "\n",
        "# Extract image links\n",
        "train_image_links = train_df['image_link'].tolist()\n",
        "test_image_links = test_df['image_link'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htlsAkAvNLzY",
        "outputId": "5b22d763-d480-4e77-c300-2d81b50dc022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting constants\n",
            "  Downloading constants-2023.2.0.tar.gz (5.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tox (from constants)\n",
            "  Downloading tox-4.18.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "INFO: pip is looking at multiple versions of constants to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting constants\n",
            "  Downloading constants-0.6.0.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: constants\n",
            "  Building wheel for constants (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for constants: filename=constants-0.6.0-py3-none-any.whl size=5457 sha256=d8dd4e299a4f543ccf70970bd20ca57f21d41438f4a6a60292f35ec6b49d59e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/96/3c/386c2342a8a1bdd317f2f250bd076c13938c6f598c4a40ec14\n",
            "Successfully built constants\n",
            "Installing collected packages: constants\n",
            "Successfully installed constants-0.6.0\n"
          ]
        }
      ],
      "source": [
        "pip install constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9PNN1az9NCtD"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import constants\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "import time\n",
        "from time import time as timer\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "import requests\n",
        "import urllib\n",
        "from PIL import Image\n",
        "\n",
        "def common_mistake(unit):\n",
        "    if unit in constants.allowed_units:\n",
        "        return unit\n",
        "    if unit.replace('ter', 'tre') in constants.allowed_units:\n",
        "        return unit.replace('ter', 'tre')\n",
        "    if unit.replace('feet', 'foot') in constants.allowed_units:\n",
        "        return unit.replace('feet', 'foot')\n",
        "    return unit\n",
        "\n",
        "def parse_string(s):\n",
        "    s_stripped = \"\" if s==None or str(s)=='nan' else s.strip()\n",
        "    if s_stripped == \"\":\n",
        "        return None, None\n",
        "    pattern = re.compile(r'^-?\\d+(\\.\\d+)?\\s+[a-zA-Z\\s]+$')\n",
        "    if not pattern.match(s_stripped):\n",
        "        raise ValueError(\"Invalid format in {}\".format(s))\n",
        "    parts = s_stripped.split(maxsplit=1)\n",
        "    number = float(parts[0])\n",
        "    unit = common_mistake(parts[1])\n",
        "    if unit not in constants.allowed_units:\n",
        "        raise ValueError(\"Invalid unit [{}] found in {}. Allowed units: {}\".format(\n",
        "            unit, s, constants.allowed_units))\n",
        "    return number, unit\n",
        "\n",
        "\n",
        "def create_placeholder_image(image_save_path):\n",
        "    try:\n",
        "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
        "        placeholder_image.save(image_save_path)\n",
        "    except Exception as e:\n",
        "        return\n",
        "\n",
        "def download_image(image_link, save_folder, retries=3, delay=3):\n",
        "    if not isinstance(image_link, str):\n",
        "        return\n",
        "\n",
        "    filename = Path(image_link).name\n",
        "    image_save_path = os.path.join(save_folder, filename)\n",
        "\n",
        "    if os.path.exists(image_save_path):\n",
        "        return\n",
        "\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            urllib.request.urlretrieve(image_link, image_save_path)\n",
        "            return\n",
        "        except:\n",
        "            time.sleep(delay)\n",
        "\n",
        "    create_placeholder_image(image_save_path) #Create a black placeholder image for invalid links/images\n",
        "\n",
        "def download_images(image_links, download_folder, allow_multiprocessing=True):\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    if allow_multiprocessing:\n",
        "        download_image_partial = partial(\n",
        "            download_image, save_folder=download_folder, retries=3, delay=3)\n",
        "\n",
        "        with multiprocessing.Pool(64) as pool:\n",
        "            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n",
        "            pool.close()\n",
        "            pool.join()\n",
        "    else:\n",
        "        for image_link in tqdm(image_links, total=len(image_links)):\n",
        "            download_image(image_link, save_folder=download_folder, retries=3, delay=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder where you want to save the images on the drive\n",
        "train_image_folder = '/content/drive/MyDrive/images/train'\n",
        "test_image_folder = '/content/drive/MyDrive/images/test'"
      ],
      "metadata": {
        "id": "R6WW62acqAbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Function to transform with fallback for unseen labels\n",
        "def label_encode_with_fallback(encoder, values):\n",
        "    unique_values = encoder.classes_\n",
        "    transformed = np.array([\n",
        "        encoder.transform([val])[0] if val in unique_values else -1 for val in values\n",
        "    ])\n",
        "    return transformed\n",
        "\n",
        "# Initialize LabelEncoders\n",
        "group_id_encoder = LabelEncoder()\n",
        "entity_name_encoder = LabelEncoder()\n",
        "\n",
        "# Fit on training data\n",
        "train_df['group_id_encoded'] = group_id_encoder.fit_transform(train_df['group_id'])\n",
        "train_df['entity_name_encoded'] = entity_name_encoder.fit_transform(train_df['entity_name'])\n",
        "\n",
        "# Transform with fallback for unseen labels\n",
        "test_df['group_id_encoded'] = label_encode_with_fallback(group_id_encoder, test_df['group_id'])\n",
        "test_df['entity_name_encoded'] = label_encode_with_fallback(entity_name_encoder, test_df['entity_name'])\n",
        "\n",
        "# Check the transformation\n",
        "print(test_df[['group_id', 'group_id_encoded', 'entity_name', 'entity_name_encoded']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVV7YNwmvj45",
        "outputId": "d150f094-5005-4ca2-e925-9846c83114f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   group_id  group_id_encoded entity_name  entity_name_encoded\n",
            "0    156839                45      height                    1\n",
            "1    792578               568       width                    7\n",
            "2    792578               568      height                    1\n",
            "3    792578               568       depth                    0\n",
            "4    792578               568       depth                    0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pd.get_dummies for one-hot encoding\n",
        "train_df_encoded = pd.get_dummies(train_df, columns=['group_id', 'entity_name'])\n",
        "test_df_encoded = pd.get_dummies(test_df, columns=['group_id', 'entity_name'])\n",
        "\n",
        "# Ensure that train and test data have the same columns after one-hot encoding\n",
        "train_df_encoded, test_df_encoded = train_df_encoded.align(test_df_encoded, join='left', axis=1, fill_value=0)\n",
        "\n",
        "# Display the encoded columns\n",
        "print(train_df_encoded.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsFapJcevshd",
        "outputId": "7d07cf8a-a38b-46a1-cc84-96b1ddf706b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          image_link    entity_value  \\\n",
            "0  https://m.media-amazon.com/images/I/61I9XdN6OF...      500.0 gram   \n",
            "1  https://m.media-amazon.com/images/I/71gSRbyXmo...         1.0 cup   \n",
            "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...      0.709 gram   \n",
            "3  https://m.media-amazon.com/images/I/612mrlqiI4...      0.709 gram   \n",
            "4  https://m.media-amazon.com/images/I/617Tl40LOX...  1400 milligram   \n",
            "\n",
            "   group_id_encoded  entity_name_encoded  group_id_101697  group_id_104874  \\\n",
            "0               535                    3            False            False   \n",
            "1               661                    2            False            False   \n",
            "2               284                    3            False            False   \n",
            "3               284                    3            False            False   \n",
            "4               520                    3            False            False   \n",
            "\n",
            "   group_id_106003  group_id_107694  group_id_107915  group_id_108478  ...  \\\n",
            "0            False            False            False            False  ...   \n",
            "1            False            False            False            False  ...   \n",
            "2            False            False            False            False  ...   \n",
            "3            False            False            False            False  ...   \n",
            "4            False            False            False            False  ...   \n",
            "\n",
            "   group_id_997333  group_id_998545  entity_name_depth  entity_name_height  \\\n",
            "0            False            False              False               False   \n",
            "1            False            False              False               False   \n",
            "2            False            False              False               False   \n",
            "3            False            False              False               False   \n",
            "4            False            False              False               False   \n",
            "\n",
            "   entity_name_item_volume  entity_name_item_weight  \\\n",
            "0                    False                     True   \n",
            "1                     True                    False   \n",
            "2                    False                     True   \n",
            "3                    False                     True   \n",
            "4                    False                     True   \n",
            "\n",
            "   entity_name_maximum_weight_recommendation  entity_name_voltage  \\\n",
            "0                                      False                False   \n",
            "1                                      False                False   \n",
            "2                                      False                False   \n",
            "3                                      False                False   \n",
            "4                                      False                False   \n",
            "\n",
            "   entity_name_wattage  entity_name_width  \n",
            "0                False              False  \n",
            "1                False              False  \n",
            "2                False              False  \n",
            "3                False              False  \n",
            "4                False              False  \n",
            "\n",
            "[5 rows x 762 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tGe7I1aj5O5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install tesseract-ocr and pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQy156HWvsbP",
        "outputId": "a92b1909-916d-4678-9896-f6be1f61e708"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (4,291 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfxyh1uNwmWx",
        "outputId": "e6011903-eadb-4860-92e2-dbd6b3e0a62a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def generate_output(index, prediction, output_file=\"output.csv\"):\n",
        "    with open(output_file, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"index\", \"prediction\"])\n",
        "        writer.writerow([index, prediction])\n",
        "\n",
        "# Example usage\n",
        "generate_output(1, \"2 gram\")\n"
      ],
      "metadata": {
        "id": "mfElP2rx1wXJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_test_out_df = pd.read_csv('/content/drive/MyDrive/dataset/sample_test_out.csv')"
      ],
      "metadata": {
        "id": "GbwUhaZE1_EX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def evaluate_model(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Example usage\n",
        "true_labels = sample_test_out_df['entity_value']\n",
        "predicted_labels = [\"2 gram\"] * len(true_labels)\n",
        "precision, recall, f1 = evaluate_model(true_labels, predicted_labels)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "MstDrEn111Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prediction format\n",
        "def format_prediction(value, unit):\n",
        "    return f\"{value} {unit}\"\n",
        "\n",
        "predictions = [format_prediction(2.0, 'gram'), format_prediction(12.5, 'centimetre')]"
      ],
      "metadata": {
        "id": "HIkJsl3a11LW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YozzJk13mZb",
        "outputId": "88ecc0d8-7c07-41ee-e5e2-cc111686c304"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def simulate_feature_extraction(image_link):\n",
        "\n",
        "    return np.random.rand() * 100  # Simulate some numeric value\n",
        "\n",
        "def predict_entity_value(feature):\n",
        "    return f\"{feature:.2f} unit\"  # Simulate a formatted prediction\n",
        "\n",
        "# Apply feature extraction and prediction\n",
        "test_df['feature'] = test_df['image_link'].apply(simulate_feature_extraction)\n",
        "test_df['prediction'] = test_df['feature'].apply(predict_entity_value)\n"
      ],
      "metadata": {
        "id": "jESRsGzk4B1v"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def evaluate_model(true_labels, predicted_labels):\n",
        "    # Placeholder function to evaluate model performance\n",
        "    # In a real scenario, use true labels and predictions for evaluation\n",
        "    precision = precision_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
        "    recall = recall_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Example usage (for simulation purposes)\n",
        "true_labels = ['2 gram'] * len(test_df)  # Placeholder for actual true labels\n",
        "predicted_labels = test_df['prediction']\n",
        "precision, recall, f1 = evaluate_model(true_labels, predicted_labels)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "8ZfdIWMF4BzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_resnet_model():\n",
        "    \"\"\"Load a pre-trained ResNet model and remove the classification layer.\"\"\"\n",
        "    resnet = models.resnet50(pretrained=True)\n",
        "    resnet = nn.Sequential(*list(resnet.children())[:-1])  # Remove the classification layer\n",
        "    resnet.eval()  # Set the model to evaluation mode\n",
        "    return resnet\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Preprocess the image for CNN feature extraction.\"\"\"\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    img = Image.open(image_path)\n",
        "    img_tensor = preprocess(img).unsqueeze(0)  # Preprocess and add batch dimension\n",
        "    return img_tensor\n",
        "\n",
        "def extract_image_features(image_path, model):\n",
        "    \"\"\"Extract features from an image using the ResNet model.\"\"\"\n",
        "    img_tensor = preprocess_image(image_path)\n",
        "    with torch.no_grad():\n",
        "        features = model(img_tensor)\n",
        "    return features.squeeze().numpy()  # Convert to numpy array\n"
      ],
      "metadata": {
        "id": "Y9pJLU-F4Bwx"
      },
      "execution_count": 34,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}